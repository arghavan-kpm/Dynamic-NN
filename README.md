# Dynamic-NN
This Dynamin net can have multiple layers and number of neurons in each layer can be changed. Implemented activation functions are 1)Linear and 2)Sigmoid. You can have 1)Drop out or 2)L2 Norm for regularization and 1)Gradient Descent or 2)Stochastic Gradient Descent for loss function.
Dataset should be placed in a directory called "DataSet" in the main directory.
For loading weights and biases you can use "Net_bgd.net" in the main directory.

